{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961e8cd7",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae6965",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "BASE_DIR = Path('data')\n",
    "TRAIN_DIR = BASE_DIR / 'seg_train'\n",
    "TEST_DIR = BASE_DIR / 'seg_test'\n",
    "PRED_DIR = BASE_DIR / 'seg_pred'\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(f\"Training directory: {TRAIN_DIR}\")\n",
    "print(f\"Test directory: {TEST_DIR}\")\n",
    "print(f\"Prediction directory: {PRED_DIR}\")\n",
    "print(f\"\\nClasses: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each class\n",
    "def count_images(directory):\n",
    "    \"\"\"Count images in each class folder.\"\"\"\n",
    "    counts = {}\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_path = directory / class_name\n",
    "        if class_path.exists():\n",
    "            counts[class_name] = len(list(class_path.glob('*')))\n",
    "        else:\n",
    "            counts[class_name] = 0\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images(TRAIN_DIR)\n",
    "test_counts = count_images(TEST_DIR)\n",
    "\n",
    "print(\"Training set distribution:\")\n",
    "for class_name, count in train_counts.items():\n",
    "    print(f\"  {class_name}: {count} images\")\n",
    "print(f\"  Total: {sum(train_counts.values())} images\")\n",
    "\n",
    "print(\"\\nTest set distribution:\")\n",
    "for class_name, count in test_counts.items():\n",
    "    print(f\"  {class_name}: {count} images\")\n",
    "print(f\"  Total: {sum(test_counts.values())} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26611810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training set\n",
    "axes[0].bar(train_counts.keys(), train_counts.values(), color='steelblue')\n",
    "axes[0].set_title('Training Set Distribution', fontsize=14)\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Test set\n",
    "axes[1].bar(test_counts.keys(), test_counts.values(), color='coral')\n",
    "axes[1].set_title('Test Set Distribution', fontsize=14)\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Number of Images')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each class\n",
    "def display_sample_images(directory, num_samples=3):\n",
    "    \"\"\"Display sample images from each class.\"\"\"\n",
    "    fig, axes = plt.subplots(NUM_CLASSES, num_samples, figsize=(12, 16))\n",
    "    \n",
    "    for i, class_name in enumerate(CLASS_NAMES):\n",
    "        class_path = directory / class_name\n",
    "        images = list(class_path.glob('*'))\n",
    "        samples = random.sample(images, min(num_samples, len(images)))\n",
    "        \n",
    "        for j, img_path in enumerate(samples):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis('off')\n",
    "            if j == 0:\n",
    "                axes[i, j].set_title(class_name.upper(), fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Each Class', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_sample_images(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c060ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image dimensions\n",
    "def analyze_image_dimensions(directory, sample_size=100):\n",
    "    \"\"\"Analyze image dimensions in the dataset.\"\"\"\n",
    "    widths, heights = [], []\n",
    "    \n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_path = directory / class_name\n",
    "        images = list(class_path.glob('*'))[:sample_size]\n",
    "        \n",
    "        for img_path in images:\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                widths.append(img.size[0])\n",
    "                heights.append(img.size[1])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return widths, heights\n",
    "\n",
    "widths, heights = analyze_image_dimensions(TRAIN_DIR)\n",
    "\n",
    "print(f\"Image dimensions analysis (sample):\")\n",
    "print(f\"  Width  - Min: {min(widths)}, Max: {max(widths)}, Mean: {np.mean(widths):.1f}\")\n",
    "print(f\"  Height - Min: {min(heights)}, Max: {max(heights)}, Mean: {np.mean(heights):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec5338",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6358d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # 20% for validation\n",
    ")\n",
    "\n",
    "# Only rescaling for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"Data generators created with augmentation for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nClass indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f308d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "def visualize_augmentation(generator, num_images=6):\n",
    "    \"\"\"Visualize augmented images.\"\"\"\n",
    "    batch = next(generator)\n",
    "    images, labels = batch[0][:num_images], batch[1][:num_images]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    class_names_list = list(train_generator.class_indices.keys())\n",
    "    \n",
    "    for i, (img, label) in enumerate(zip(images, labels)):\n",
    "        axes[i].imshow(img)\n",
    "        class_idx = np.argmax(label)\n",
    "        axes[i].set_title(f'Class: {class_names_list[class_idx]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Augmented Training Images', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_augmentation(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8eddd4",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "We'll build two models:\n",
    "1. A custom CNN from scratch\n",
    "2. A transfer learning model using a pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72436e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CNN Model\n",
    "def build_custom_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES):\n",
    "    \"\"\"Build a custom CNN model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First Conv Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fourth Conv Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and display model\n",
    "custom_model = build_custom_cnn()\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Model using MobileNetV2\n",
    "def build_transfer_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES):\n",
    "    \"\"\"Build a transfer learning model using MobileNetV2.\"\"\"\n",
    "    \n",
    "    # Load pre-trained MobileNetV2\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build transfer learning model\n",
    "transfer_model = build_transfer_model()\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which model to train (change this to switch models)\n",
    "MODEL_TYPE = 'transfer'  # 'custom' or 'transfer'\n",
    "\n",
    "if MODEL_TYPE == 'custom':\n",
    "    model = custom_model\n",
    "    print(\"Using Custom CNN Model\")\n",
    "else:\n",
    "    model = transfer_model\n",
    "    print(\"Using Transfer Learning Model (MobileNetV2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d20de",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks defined:\")\n",
    "print(\"  - EarlyStopping (patience=5)\")\n",
    "print(\"  - ReduceLROnPlateau (factor=0.2, patience=3)\")\n",
    "print(\"  - ModelCheckpoint (save best model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73937373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cebfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation accuracy/loss.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    axes[0].set_title('Model Accuracy', fontsize=14)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    axes[1].set_title('Model Loss', fontsize=14)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737603b",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8df35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = keras.models.load_model('best_model.keras')\n",
    "print(\"Best model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ea5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = best_model.evaluate(test_generator, verbose=1)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "test_generator.reset()\n",
    "predictions = best_model.predict(test_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Class names\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(f\"Total predictions: {len(predicted_classes)}\")\n",
    "print(f\"Total true labels: {len(true_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8092574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb606e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(class_names, per_class_accuracy * 100, color='steelblue')\n",
    "plt.axhline(y=test_accuracy * 100, color='red', linestyle='--', label=f'Overall Accuracy: {test_accuracy*100:.2f}%')\n",
    "plt.title('Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, per_class_accuracy):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{acc*100:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328f3d2",
   "metadata": {},
   "source": [
    "## 7. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict a single image\n",
    "def predict_image(model, image_path, class_names):\n",
    "    \"\"\"Predict class for a single image.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img_resized = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    img_array = np.array(img_resized) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    predicted_class = class_names[np.argmax(prediction)]\n",
    "    confidence = np.max(prediction) * 100\n",
    "    \n",
    "    return predicted_class, confidence, prediction[0]\n",
    "\n",
    "# Display predictions with confidence\n",
    "def display_predictions(model, directory, class_names, num_samples=9):\n",
    "    \"\"\"Display predictions for random test images.\"\"\"\n",
    "    all_images = []\n",
    "    for class_name in class_names:\n",
    "        class_path = Path(directory) / class_name\n",
    "        all_images.extend(list(class_path.glob('*')))\n",
    "    \n",
    "    samples = random.sample(all_images, min(num_samples, len(all_images)))\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(samples):\n",
    "        true_class = img_path.parent.name\n",
    "        predicted_class, confidence, _ = predict_image(model, img_path, class_names)\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        color = 'green' if predicted_class == true_class else 'red'\n",
    "        axes[i].set_title(f'True: {true_class}\\nPred: {predicted_class} ({confidence:.1f}%)', \n",
    "                         color=color, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions on Test Images', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_predictions(best_model, TEST_DIR, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on images in seg_pred folder\n",
    "def predict_folder(model, pred_dir, class_names):\n",
    "    \"\"\"Make predictions on all images in a folder.\"\"\"\n",
    "    pred_path = Path(pred_dir)\n",
    "    \n",
    "    if not pred_path.exists():\n",
    "        print(f\"Prediction folder {pred_dir} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    images = list(pred_path.glob('*'))\n",
    "    image_files = [f for f in images if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in prediction folder.\")\n",
    "        return\n",
    "    \n",
    "    results = []\n",
    "    for img_path in image_files:\n",
    "        predicted_class, confidence, probs = predict_image(model, img_path, class_names)\n",
    "        results.append({\n",
    "            'filename': img_path.name,\n",
    "            'predicted_class': predicted_class,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Predict on seg_pred folder\n",
    "pred_results = predict_folder(best_model, PRED_DIR, class_names)\n",
    "if pred_results is not None and len(pred_results) > 0:\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(pred_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a000fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('intel_image_classifier.keras')\n",
    "print(\"Model saved as 'intel_image_classifier.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9da06",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Explored the dataset** - Analyzed the distribution of images across 6 classes\n",
    "2. **Preprocessed the data** - Applied data augmentation and normalization\n",
    "3. **Built models** - Created both a custom CNN and a transfer learning model\n",
    "4. **Trained the model** - Used callbacks for early stopping and learning rate reduction\n",
    "5. **Evaluated performance** - Generated confusion matrix and classification report\n",
    "6. **Made predictions** - Demonstrated how to use the model for inference\n",
    "\n",
    "### Next Steps\n",
    "- Fine-tune the transfer learning model by unfreezing some layers\n",
    "- Experiment with different architectures (ResNet, EfficientNet)\n",
    "- Try different hyperparameters and augmentation strategies\n",
    "- Implement cross-validation for more robust evaluation\n",
    "- Deploy the model as a web service or mobile app"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
